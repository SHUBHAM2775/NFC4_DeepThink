# Ollama Configuration
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.2

# Flask Configuration
FLASK_ENV=development
FLASK_DEBUG=true
FLASK_PORT=5001

# AI Assistant Configuration
MAX_MEMORY_ENTRIES=100
DEFAULT_LANGUAGE=english

# Logging Configuration
LOG_LEVEL=INFO
